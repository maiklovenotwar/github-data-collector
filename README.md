# GitHub Data Collector

Ein leistungsstarkes ETL-System zur Sammlung von GitHub-Daten Ã¼ber Repositories, Contributoren und Organisationen. Dieses System konzentriert sich auf die effiziente Sammlung und Speicherung von GitHub-Daten in einer SQLite-Datenbank fÃ¼r externe Analysezwecke.

## ğŸŒ Projektfokus

Dieses Projekt konzentriert sich ausschlieÃŸlich auf die effiziente Sammlung von GitHub-Daten:

1. **Sammlung umfassender GitHub-Repository-Daten** mit effizienten Sammlungsstrategien
2. **Erfassung von Contributor-Informationen** einschlieÃŸlich Standortdaten
3. **Sammlung von Organisationsdaten** mit Metadaten und Standortinformationen
4. **Geokodierung von Standortdaten** zur Anreicherung mit LÃ¤nder- und Regionsinformationen
5. **Speicherung aller Daten in einer SQLite- oder MySQL-Datenbank** fÃ¼r externe Analysezwecke

## ğŸŒŸ Hauptfunktionen

- **Effiziente GitHub API-Integration**: Optimiert fÃ¼r die Sammlung detaillierter Repository-, Contributor- und Organisationsmetadaten
- **Geografische Anreicherung**: Extrahiert und geokodiert Standortdaten von Mitwirkenden und Organisationen
- **UnterstÃ¼tzung fÃ¼r MySQL und SQLite**: Die Datenbank kann Ã¼ber die Umgebungsvariable `DATABASE_URL` als SQLite- oder MySQL-URL angegeben werden (siehe unten).
- **Effiziente Sammlungsstrategien**:
  - Sternbasierte Sammlung fÃ¼r beliebte Repositories
  - Zeitraumbasierte Sammlung fÃ¼r historische Daten mit optimierter PeriodengrÃ¶ÃŸe
- **Leistungsoptimierungen**:
  - Token-Pool-Management fÃ¼r die Handhabung von GitHub API-Ratenlimits
  - Intelligentes Caching-System zur Reduzierung von API-Aufrufen
  - Fortschrittsverfolgung mit WiederaufnahmefÃ¤higkeit
  - **Verbesserte NebenlÃ¤ufigkeit fÃ¼r SQLite**: Der standardmÃ¤ÃŸig aktivierte WAL-Modus (Write-Ahead Logging) fÃ¼r SQLite-Datenbanken reduziert Sperrkonflikte erheblich und ermÃ¶glicht eine stabilere parallele AusfÃ¼hrung von Sammel- und Anreicherungsskripten.
- **Einfacher Datenexport**: Export der gesammelten Daten in CSV-Dateien fÃ¼r externe Analysen

## ğŸš€ Erste Schritte

### Voraussetzungen

- Python 3.8+
- GitHub API-Token(s)
- SQLAlchemy-kompatible Datenbank (SQLite oder MySQL)

**UnterstÃ¼tzte Datenbanken:**
- SQLite (Standard): `DATABASE_URL=sqlite:///data/github_data.db`
- MySQL: `DATABASE_URL=mysql+pymysql://user:pass@localhost/github_data`

Die Umgebungsvariable `DATABASE_URL` kann in der `.env`-Datei gesetzt werden. Alle Skripte erkennen diese Variable automatisch. Alternativ kann bei den meisten Skripten der Parameter `--db-path` verwendet werden (wird automatisch zu einer SQLAlchemy-URL umgewandelt, falls nÃ¶tig).

### Installation

```bash
# Repository klonen
git clone https://github.com/yourusername/github-data-collector.git
cd github-data-collector

# Virtuelle Umgebung erstellen und aktivieren
python -m venv venv
source venv/bin/activate  # Unter Windows: venv\Scripts\activate

# AbhÃ¤ngigkeiten installieren
pip install -r requirements.txt

# Umgebungsvariablen konfigurieren
cp .env.template .env
# Bearbeite .env und fÃ¼ge deine GitHub API-Token hinzu
```

### Grundlegende Verwendung

```bash
# GitHub-Repositories sammeln
python scripts/collect_repositories.py --time-range month --min-stars 100

# Standortdaten geokodieren
python scripts/update_location_geocoding.py

# Daten in CSV-Dateien exportieren
python scripts/export_tables_to_csv.py

# --- Parallele AusfÃ¼hrung (Empfohlen fÃ¼r SQLite) ---
# Aufgrund des aktivierten WAL-Modus fÃ¼r SQLite kÃ¶nnen das Sammeln von Repositories
# und die Geokodierung nun effizient parallel ausgefÃ¼hrt werden, um Zeit zu sparen:
# Terminal 1:
# python scripts/collect_repositories.py --interactive 
# Terminal 2:
# python scripts/update_location_geocoding.py
```

## ğŸ“Š Datenmodell

### Haupttabellen

1. **Contributors**: GitHub-Benutzer mit Standortinformationen
2. **Organizations**: GitHub-Organisationen mit Standortinformationen
3. **Repositories**: GitHub-Repositories mit Metadaten und Statistiken

## ğŸ“ Projektstruktur

```
github-data-collector/
â”œâ”€â”€ docs/                  # Dokumentation
â”œâ”€â”€ scripts/               # AusfÃ¼hrbare Skripte
â”‚   â”œâ”€â”€ collect_repositories.py     # Sammlung von Repositories
â”‚   â”œâ”€â”€ update_location_geocoding.py # Geokodierung von Standorten
â”‚   â””â”€â”€ export_tables_to_csv.py     # Export von Daten
â”œâ”€â”€ src/                   # Quellcode
â”‚   â””â”€â”€ github_collector/   # Hauptpaket
â”‚       â”œâ”€â”€ api/           # GitHub API-Integration
â”‚       â”œâ”€â”€ database/      # Datenbankmodelle und -operationen
â”‚       â”œâ”€â”€ geocoding/     # Geokodierungsdienste
â”‚       â””â”€â”€ utils/         # Hilfsfunktionen
â”œâ”€â”€ tests/                 # Tests
â”œâ”€â”€ .env.template          # Vorlage fÃ¼r Umgebungsvariablen
â”œâ”€â”€ requirements.txt       # ProjektabhÃ¤ngigkeiten
â””â”€â”€ README.md              # Projektdokumentation
```

## Tests ausfÃ¼hren

Stelle sicher, dass pytest installiert ist:

    pip install pytest

FÃ¼hre dann die Tests mit folgendem Befehl aus:

    PYTHONPATH=src pytest

Optional fÃ¼r Coverage:

    pip install pytest-cov
    PYTHONPATH=src pytest --cov=github_collector

## ğŸ“ Lizenz

Dieses Projekt ist unter der MIT-Lizenz lizenziert - siehe die [LICENSE](LICENSE)-Datei fÃ¼r Details.

---

# GitHub Data Collector

A powerful ETL system for collecting GitHub data on repositories, contributors, and organizations. This system focuses on efficient data collection and storage in a SQLite database for external analysis purposes.

## ğŸŒ Project Focus

This project focuses exclusively on efficient data collection:

1. **Comprehensive GitHub repository data collection** with efficient collection strategies
2. **Contributor information collection** including location data
3. **Organization data collection** with metadata and location information
4. **Geocoding of location data** to enrich with country and region information
5. **Storage of all data in a SQLite database** for external analysis purposes

## ğŸŒŸ Main Features

- **Efficient GitHub API integration**: Optimized for collecting detailed repository, contributor, and organization metadata
- **Geographic enrichment**: Extracts and geocodes location data from contributors and organizations
- **Efficient collection strategies**:
  - Star-based collection for popular repositories
  - Time-based collection for historical data with optimized period size
- **Performance optimizations**:
  - Token pool management for handling GitHub API rate limits
  - Intelligent caching system to reduce API calls
  - Progress tracking with resume capability
  - **Improved Concurrency for SQLite**: Write-Ahead Logging (WAL) mode is enabled by default for SQLite databases, significantly reducing locking contention and allowing for more stable parallel execution of collection and enrichment scripts.
- **Easy data export**: Export collected data to CSV files for external analysis

## ğŸš€ Getting Started

### Prerequisites

- Python 3.8+
- GitHub API token(s)
- SQLAlchemy-compatible database (default: SQLite)

### Installation

```bash
# Clone repository
git clone https://github.com/yourusername/github-data-collector.git
cd github-data-collector

# Create and activate virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Configure environment variables
cp .env.template .env
# Edit .env and add your GitHub API token
```

### Basic Usage

```bash
# Collect GitHub repositories
python scripts/collect_repositories.py --time-range month --min-stars 100

# Geocode location data
python scripts/update_location_geocoding.py

# Export data to CSV files
python scripts/export_tables_to_csv.py

# --- Parallel Execution (Recommended for SQLite) ---
# Due to the enabled WAL mode for SQLite, repository collection and geocoding
# can now be run efficiently in parallel to save time:
# Terminal 1:
# python scripts/collect_repositories.py --interactive
# Terminal 2:
# python scripts/update_location_geocoding.py
```

## ğŸ“Š Data Model

### Main Tables

1. **Contributors**: GitHub users with location information
2. **Organizations**: GitHub organizations with location information
3. **Repositories**: GitHub repositories with metadata and statistics

## ğŸ“ Project Structure

```
github-data-collector/
â”œâ”€â”€ docs/                  # Documentation
â”œâ”€â”€ scripts/               # Executable scripts
â”‚   â”œâ”€â”€ collect_repositories.py     # Repository collection
â”‚   â”œâ”€â”€ update_location_geocoding.py # Location geocoding
â”‚   â””â”€â”€ export_tables_to_csv.py     # Data export
â”œâ”€â”€ src/                   # Source code
â”‚   â””â”€â”€ github_collector/   # Main package
â”‚       â”œâ”€â”€ api/           # GitHub API integration
â”‚       â”œâ”€â”€ database/      # Database models and operations
â”‚       â”œâ”€â”€ geocoding/     # Geocoding services
â”‚       â””â”€â”€ utils/         # Utility functions
â”œâ”€â”€ tests/                 # Tests
â”œâ”€â”€ .env.template          # Environment variable template
â”œâ”€â”€ requirements.txt       # Project dependencies
â””â”€â”€ README.md              # Project documentation
```

## Running Tests

Make sure pytest is installed:

    pip install pytest

Then run the tests with the following command:

    PYTHONPATH=src pytest

Optional for coverage:

    pip install pytest-cov
    PYTHONPATH=src pytest --cov=github_collector

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
